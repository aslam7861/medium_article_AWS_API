<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Automation on Airports using API and AWS</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Automation on Airports using API and AWS</h1>
</header>
<section data-field="subtitle" class="p-summary">
In this twenty-first century, technology has taken a major place in the real world. There are many things that can be done by sitting from…
</section>
<section data-field="body" class="e-content">
<section name="c0b4" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="06e1" id="06e1" class="graf graf--h3 graf--hasDropCapModel graf--leading graf--title"><strong class="markup--strong markup--h3-strong">Automation on Airports using API and AWS </strong></h3><p name="d452" id="d452" class="graf graf--p graf-after--h3">In this twenty-first century, technology has taken a major place in the real world. There are many things that can be done by sitting from a lovable place. We all can see in our daily life how dependent we are nowadays with technology . Today, I am discussing here to find all the informations of major airports of Germany . Many taxis, scooters and bicycle renting companies can get benefited with the informations which I explain in this medium article.</p><p name="77fc" id="77fc" class="graf graf--p graf-after--p">The big advantage of modern technology to a company is optimising eveything and increasing the profit. For example, if the scooters company distributed many rented scooters to a big airports where there was maximum chance of raining then the company would have to bear the costs while distributing the scooters to different places.</p><figure name="ce78" id="ce78" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gNblB-OOm3dEYEiXe9xVrw.png" data-width="924" data-height="262" src="https://cdn-images-1.medium.com/max/800/1*gNblB-OOm3dEYEiXe9xVrw.png"><figcaption class="imageCaption">google.com</figcaption></figure><p name="937e" id="937e" class="graf graf--p graf-after--figure">Once the company knows the weather conditions and the number of flights landing in each big cities then they can analyse the right quantity of scooters/taxis to be distributed in each places for renters.</p><h4 name="19ee" id="19ee" class="graf graf--h4 graf-after--p">Web scrapping:</h4><p name="a56b" id="a56b" class="graf graf--p graf-after--h4">We use Web scraping to collect the structured web data in an automation fashion. Web scrapping involves downloading a page and extracting the informations from it. This is the one of the important tool to bring the informations from wikipedia. The content of a page may be parsed and reformatted, and its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. For example we collect the informations of all the flights status of diffferent airports of Germany using web scrapping(using Beautifulsoup) and bring out the necessary information which we require.</p><figure name="5026" id="5026" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1_UYXjS0q0dc3126FDN6Lg.png" data-width="294" data-height="210" src="https://cdn-images-1.medium.com/max/800/1*1_UYXjS0q0dc3126FDN6Lg.png"></figure><p name="d0a4" id="d0a4" class="graf graf--p graf-after--figure">To use the webscrapping we use API keys which you have to find on your own</p><pre name="8eed" id="8eed" class="graf graf--pre graf-after--p">OWM_key = &quot;your_key&quot;<br>flight_api_key = &quot;your_api_key&quot;</pre><p name="1f42" id="1f42" class="graf graf--p graf-after--pre">We collect informations of all cities of Germany in a dataframe df_cities which have a large airports using BeautifulSoup function.</p><pre name="bba7" id="bba7" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">import</strong> requests<br><strong class="markup--strong markup--pre-strong">from</strong> bs4 <strong class="markup--strong markup--pre-strong">import</strong> BeautifulSoup <strong class="markup--strong markup--pre-strong">as</strong> bs<br><strong class="markup--strong markup--pre-strong">import</strong> pandas <strong class="markup--strong markup--pre-strong">as</strong> pd<br><strong class="markup--strong markup--pre-strong">import</strong> unicodedata<br>city_lists=[‘Berlin’, ‘Dresden’, ‘Frankfurt am Main’, ‘Münster’, ‘Hamburg’ ‘Cologne’, ‘Düsseldorf’, ‘Munich’, ‘Nuremberg’, ‘Leipzig’, ‘Stuttgart’, ‘Hannover’,‘Bremen’, ‘Dortmund’, ‘Karlsruhe’]</pre><pre name="3688" id="3688" class="graf graf--pre graf-after--pre">countries=[&quot;DE&quot; for i in rannge(den(city_lists))]</pre><pre name="5926" id="5926" class="graf graf--pre graf-after--pre">airports_icao=[&#39;EDDB&#39;,&#39;EDDC&#39;, &#39;EDDF&#39;, &#39;EDDG&#39;, &#39;EDDH&#39;, &#39;EDDK&#39;,&#39;EDDL&#39;, &#39;EDDM&#39;, &#39;EDDN&#39;, &#39;EDDP&#39;, &#39;EDDS&#39;, &#39;EDDV&#39;, &#39;EDDW&#39;, &#39;EDLW&#39;, &#39;EDSB&#39;]</pre><pre name="00eb" id="00eb" class="graf graf--pre graf-after--pre">cities<strong class="markup--strong markup--pre-strong">=</strong>city_lists<br><strong class="markup--strong markup--pre-strong">def</strong> City_info(soup):<br>    <br>    ret_dict <strong class="markup--strong markup--pre-strong">=</strong> {}<br>    ret_dict[&#39;city&#39;] <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>h1<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>    <br>    <br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedrow:-soup-contains(&quot;Mayor&quot;)&gt;.infobox-label&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        i <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedrow:-soup-contains(&quot;Mayor&quot;)&gt;.infobox-label&#39;)<br>        mayor_name_html <strong class="markup--strong markup--pre-strong">=</strong> i<strong class="markup--strong markup--pre-strong">.</strong>find_next_sibling()<br>        mayor_name <strong class="markup--strong markup--pre-strong">=</strong> unicodedata<strong class="markup--strong markup--pre-strong">.</strong>normalize(&#39;NFKD&#39;,mayor_name_html<strong class="markup--strong markup--pre-strong">.</strong>get_text())<br>        ret_dict[&#39;mayor&#39;]  <strong class="markup--strong markup--pre-strong">=</strong> mayor_name<br>    <br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedrow:-soup-contains(&quot;City&quot;)&gt;.infobox-label&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        j <strong class="markup--strong markup--pre-strong">=</strong>  soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedrow:-soup-contains(&quot;City&quot;)&gt;.infobox-label&#39;)<br>        area <strong class="markup--strong markup--pre-strong">=</strong> j<strong class="markup--strong markup--pre-strong">.</strong>find_next_sibling(&#39;td&#39;)<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>        ret_dict[&#39;city_size&#39;] <strong class="markup--strong markup--pre-strong">=</strong> unicodedata<strong class="markup--strong markup--pre-strong">.</strong>normalize(&#39;NFKD&#39;,area)<br><br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedtoprow:-soup-contains(&quot;Elevation&quot;)&gt;.infobox-data&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        k <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedtoprow:-soup-contains(&quot;Elevation&quot;)&gt;.infobox-data&#39;)<br>        elevation_html <strong class="markup--strong markup--pre-strong">=</strong> k<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>        ret_dict[&#39;elevation&#39;] <strong class="markup--strong markup--pre-strong">=</strong> unicodedata<strong class="markup--strong markup--pre-strong">.</strong>normalize(&#39;NFKD&#39;,elevation_html)<br>    <br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedtoprow:-soup-contains(&quot;Population&quot;)&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        l <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.mergedtoprow:-soup-contains(&quot;Population&quot;)&#39;)<br>        c_pop <strong class="markup--strong markup--pre-strong">=</strong> l<strong class="markup--strong markup--pre-strong">.</strong>findNext(&#39;td&#39;)<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>        ret_dict[&#39;city_population&#39;] <strong class="markup--strong markup--pre-strong">=</strong> c_pop<br>    <br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.infobox-label&gt;[title^=Urban]&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        m <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.infobox-label&gt;[title^=Urban]&#39;)<br>        u_pop <strong class="markup--strong markup--pre-strong">=</strong> m<strong class="markup--strong markup--pre-strong">.</strong>findNext(&#39;td&#39;)<br>        ret_dict[&#39;urban_population&#39;] <strong class="markup--strong markup--pre-strong">=</strong> u_pop<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br><br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.infobox-label&gt;[title^=Metro]&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        n <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.infobox-label&gt;[title^=Metro]&#39;)<br>        m_pop <strong class="markup--strong markup--pre-strong">=</strong> n<strong class="markup--strong markup--pre-strong">.</strong>findNext(&#39;td&#39;)<br>        ret_dict[&#39;metro_population&#39;] <strong class="markup--strong markup--pre-strong">=</strong> m_pop<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>    <br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.latitude&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:<br>        o <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.latitude&#39;)<br>        ret_dict[&#39;lat&#39;] <strong class="markup--strong markup--pre-strong">=</strong> o<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br><br>    <strong class="markup--strong markup--pre-strong">if</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.longitude&#39;) <strong class="markup--strong markup--pre-strong">!=</strong> <strong class="markup--strong markup--pre-strong">None</strong>:    <br>        p <strong class="markup--strong markup--pre-strong">=</strong> soup<strong class="markup--strong markup--pre-strong">.</strong>select_one(&#39;.longitude&#39;)<br>        ret_dict[&#39;long&#39;] <strong class="markup--strong markup--pre-strong">=</strong> p<strong class="markup--strong markup--pre-strong">.</strong>get_text()<br>    <br>    <strong class="markup--strong markup--pre-strong">return</strong> ret_dict<br><br>list_of_city_info <strong class="markup--strong markup--pre-strong">=</strong> []<br><strong class="markup--strong markup--pre-strong">for</strong> city <strong class="markup--strong markup--pre-strong">in</strong> cities:<br>    url <strong class="markup--strong markup--pre-strong">=</strong> &#39;https://en.wikipedia.org/wiki/{}&#39;<strong class="markup--strong markup--pre-strong">.</strong>format(city)<br>    web <strong class="markup--strong markup--pre-strong">=</strong> requests<strong class="markup--strong markup--pre-strong">.</strong>get(url,&#39;html.parser&#39;)<br>    soup <strong class="markup--strong markup--pre-strong">=</strong> bs(web<strong class="markup--strong markup--pre-strong">.</strong>content)<br>    list_of_city_info<strong class="markup--strong markup--pre-strong">.</strong>append(City_info(soup))<br>df_cities <strong class="markup--strong markup--pre-strong">=</strong> pd<strong class="markup--strong markup--pre-strong">.</strong>DataFrame(list_of_city_info)<br>df_cities.head(5)</pre><figure name="1efa" id="1efa" class="graf graf--figure graf-after--pre"><img class="graf-image" data-image-id="1*SqO3gEVpM09vZ6-3QgWCJA.png" data-width="1700" data-height="624" src="https://cdn-images-1.medium.com/max/800/1*SqO3gEVpM09vZ6-3QgWCJA.png"></figure><p name="eaa5" id="eaa5" class="graf graf--p graf--empty graf-after--figure"><br></p><p name="5673" id="5673" class="graf graf--p graf-after--p">We collect weather information using web scrapping with OWM API key:</p><pre name="61da" id="61da" class="graf graf--pre graf-after--p"># look for the fields that could be relevant: <br># better field descriptions <a href="https://www.weatherbit.io/api/weather-forecast-5-day" data-href="https://www.weatherbit.io/api/weather-forecast-5-day" class="markup--anchor markup--pre-anchor" rel="nofollow noopener" target="_blank">https://www.weatherbit.io/api/weather-forecast-5-day</a><br>all_weather=[]<br># datetime, temperature, wind, prob_perc, rain_qty, snow = [], [], [], [], [], []<br># for forecast_api in forecast_apis:<br>    <br>for i in range(len(city_lists)):<br>    city=city_lists[i]<br>    country=countries[i]<br>    #response=responses[i]<br>    forecast_api = responses[i].json()[&#39;list&#39;]<br>    weather_info = []<br>    for forecast_3h in forecast_api: <br>        weather_hour = {}<br>        # datetime utc<br>        weather_hour[&#39;datetime&#39;] = forecast_3h[&#39;dt_txt&#39;]<br>        # temperature <br>        weather_hour[&#39;temperature&#39;] = forecast_3h[&#39;main&#39;][&#39;temp&#39;]<br>        # wind<br>        weather_hour[&#39;wind&#39;] = forecast_3h[&#39;wind&#39;][&#39;speed&#39;]<br>        # probability precipitation <br>        try: weather_hour[&#39;prob_perc&#39;] = float(forecast_3h[&#39;pop&#39;])<br>        except: weather_hour[&#39;prob_perc&#39;] = 0<br>        # rain<br>        try: weather_hour[&#39;rain_qty&#39;] = float(forecast_3h[&#39;rain&#39;][&#39;3h&#39;])<br>        except: weather_hour[&#39;rain_qty&#39;] = 0<br>        # wind <br>        try: weather_hour[&#39;snow&#39;] = float(forecast_3h[&#39;snow&#39;][&#39;3h&#39;])<br>        except: weather_hour[&#39;snow&#39;] = 0<br>            <br>        weather_hour[&#39;municipality_iso_country&#39;] = city + &#39;,&#39; + country<br>        weather_info.append(weather_hour)<br>    all_weather.append(weather_info)<br>        <br>all_weather_data = pd.concat([pd.DataFrame(a) for a in all_weather])</pre><h4 name="7fcb" id="7fcb" class="graf graf--h4 graf-after--pre">Airports detail of Germany using API keys of Aerodatabox:</h4><figure name="d4e7" id="d4e7" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="1*7roZbOu4NEe8Jzee8RQZFw.jpeg" data-width="242" data-height="208" src="https://cdn-images-1.medium.com/max/800/1*7roZbOu4NEe8Jzee8RQZFw.jpeg"><figcaption class="imageCaption">google.com</figcaption></figure><p name="5a8c" id="5a8c" class="graf graf--p graf-after--figure">In the following code we are extracting  data using API of Aerodatabox of cities with time interval of 9 hours from actual time:</p><pre name="424a" id="424a" class="graf graf--pre graf-after--p">import requests<br>from IPython.display import JSON<br>responses=[]<br>from datetime import datetime, timedelta</pre><pre name="3768" id="3768" class="graf graf--pre graf-after--pre">for i in range(len(airports_icao)):<br>    to_local_time = datetime.now().strftime(&#39;%Y-%m-%dT%H:00&#39;)<br>    from_local_time = (datetime.now() + timedelta(hours=9)).strftime(&#39;%Y-%m-%dT%H:00&#39;)<br>    url = f&quot;<a href="https://aerodatabox.p.rapidapi.com/flights/airports/icao/%7Bairports_icao[i]%7D/%7Bto_local_time%7D/%7Bfrom_local_time" data-href="https://aerodatabox.p.rapidapi.com/flights/airports/icao/{airports_icao[i]}/{to_local_time}/{from_local_time" class="markup--anchor markup--pre-anchor" rel="nofollow noopener noopener" target="_blank">https://aerodatabox.p.rapidapi.com/flights/airports/icao/{airports_icao[i]}/{to_local_time}/{from_local_time</a>}&quot;<br>    querystring = {&quot;withLeg&quot;:&quot;true&quot;,&quot;withCancelled&quot;:&quot;true&quot;,&quot;withCodeshared&quot;:&quot;true&quot;,&quot;withCargo&quot;:&quot;true&quot;,&quot;withPrivate&quot;:&quot;false&quot;,&quot;withLocation&quot;:&quot;false&quot;}<br>    headers = {<br>        &#39;x-rapidapi-host&#39;: &quot;aerodatabox.p.rapidapi.com&quot;,<br>        &#39;x-rapidapi-key&#39;: flight_api_key<br>        }<br>    responses.append(requests.request(&quot;GET&quot;, url, headers=headers, params=querystring))</pre><p name="39a1" id="39a1" class="graf graf--p graf-after--pre">We collected all the information in <strong class="markup--strong markup--p-strong">responses. </strong>We apply <strong class="markup--strong markup--p-strong">.json()</strong> for each item of responses and collect the informations of flights which are landing in different cities and form a data frame <strong class="markup--strong markup--p-strong">arrival_cities </strong>as computed below<strong class="markup--strong markup--p-strong">:</strong></p><pre name="0d3c" id="0d3c" class="graf graf--pre graf-after--p">import requests<br>from IPython.display import JSON<br>responses=[]<br>from datetime import datetime, timedelta</pre><pre name="a50f" id="a50f" class="graf graf--pre graf-after--pre">for i in range(len(airports_icao)):<br><br>arrivals_list=[]<br>for i in range(len(responses)):<br>#for response in responses:<br>    arrivals_list.append(responses[i].json()[&#39;arrivals&#39;])</pre><pre name="c723" id="c723" class="graf graf--pre graf-after--pre">def get_flight_info(flight_json, icao):<br>    # terminal<br>    try: terminal = flight_json[&#39;arrival&#39;][&#39;terminal&#39;]<br>    except: terminal = None<br>    # aircraft<br>    try: aircraft = flight_json[&#39;aircraft&#39;][&#39;model&#39;]<br>    except: aircraft = None</pre><pre name="8d0f" id="8d0f" class="graf graf--pre graf-after--pre">return {<br>        &#39;dep_airport&#39;:flight_json[&#39;departure&#39;][&#39;airport&#39;][&#39;name&#39;],<br>        &#39;sched_arr_loc_time&#39;:flight_json[&#39;arrival&#39;][&#39;scheduledTimeLocal&#39;],<br>        &#39;terminal&#39;:terminal,<br>        &#39;status&#39;:flight_json[&#39;status&#39;],<br>        &#39;aircraft&#39;:aircraft,<br>        &#39;icao_code&#39;:icao<br>        #&#39;icao_code&#39;:airport_icoa<br>    }</pre><pre name="5330" id="5330" class="graf graf--pre graf-after--pre">import pandas as pd<br>pds=[]<br>for i in range(len(city_lists)):<br>    pds.append(pd.DataFrame([get_flight_info(flight, airports_icao[i]) for flight in arrivals_list[i]]))</pre><pre name="f407" id="f407" class="graf graf--pre graf-after--pre">print([a.shape for a in pds])<br>arrivals_cities=pd.concat(pds)</pre><h4 name="92b4" id="92b4" class="graf graf--h4 graf-after--pre">SQL Alchemy:</h4><figure name="fdc0" id="fdc0" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="1*j7KCFGTuxk3Y_T6vcpsh6w.png" data-width="682" data-height="136" src="https://cdn-images-1.medium.com/max/800/1*j7KCFGTuxk3Y_T6vcpsh6w.png"></figure><p name="dbf3" id="dbf3" class="graf graf--p graf-after--figure">SQLAlchemy is the <strong class="markup--strong markup--p-strong">Python SQL toolkit</strong> and Object Relational Mapper that gives application developers the full power and flexibility of SQL. Python has different libraries to bring necessary informations using APIs. One can clean the data using pandas in python. To produce a database in SQL we create first a Schema in MySQL using the following one line code:</p><pre name="775d" id="775d" class="graf graf--pre graf-after--p">CREATE DATABASE project;</pre><p name="241f" id="241f" class="graf graf--p graf-after--pre">After creating the database the following code connects our python code to SQL:</p><pre name="0894" id="0894" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">import</strong> pandas <strong class="markup--strong markup--pre-strong">as</strong> pd<br><br>schema<strong class="markup--strong markup--pre-strong">= </strong>&quot;project&quot;<br>host<strong class="markup--strong markup--pre-strong">=</strong>&quot;abcd&quot;<br>user<strong class="markup--strong markup--pre-strong">=</strong>&quot;abcd&quot;<br>password<strong class="markup--strong markup--pre-strong">=</strong>&quot;password&quot;<br>port<strong class="markup--strong markup--pre-strong">=</strong>3306<br>con <strong class="markup--strong markup--pre-strong">=</strong> f&#39;mysql+pymysql://{user}:{password}@{host}:{port}/{schema}&#39;</pre><p name="7a47" id="7a47" class="graf graf--p graf-after--pre">Once the connection is created between python and SQL Schema, we just need to hit the following code:</p><pre name="06d7" id="06d7" class="graf graf--pre graf-after--p">all_weather_data.to_sql(&#39;weather&#39;, if_exists=&#39;append&#39;, con=con, index=False)<br>arrivals_cities.to_sql(&#39;arrivals&#39;, if_exists=&#39;append&#39;, con=con, index=False)<br>df_cities.to_sql(&#39;cities&#39;, if_exists=&#39;append&#39;, con=con, index=False)</pre><p name="4c46" id="4c46" class="graf graf--p graf-after--pre">in Python which sends all the information in our Schema. If you need more informations to be included then you extract informations using API keys and push it in your schema.</p><p name="e0f6" id="e0f6" class="graf graf--p graf-after--p">I have sent all the informations in my schema known as ‘project’ and produced the following ERR diagram:</p><figure name="10ba" id="10ba" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zPpcG1IZ47uB76YKb28UZw.png" data-width="584" data-height="580" src="https://cdn-images-1.medium.com/max/800/1*zPpcG1IZ47uB76YKb28UZw.png"></figure><p name="774d" id="774d" class="graf graf--p graf--empty graf-after--figure"><br></p><h4 name="149a" id="149a" class="graf graf--h4 graf-after--p">SQL-Tableau: </h4><p name="00ad" id="00ad" class="graf graf--p graf-after--h4">The data base ‘project’ consists of information in the time between 15:20–00:20 of August 09, 2022(<strong class="markup--strong markup--p-strong">For you change the time accordingly</strong>) from which I constructed a table which explains number of flights landing with other details:</p><figure name="a411" id="a411" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*QWJ5OgTdnoc5lQq5VcaD7A.png" data-width="1330" data-height="670" src="https://cdn-images-1.medium.com/max/800/1*QWJ5OgTdnoc5lQq5VcaD7A.png"></figure><p name="81a9" id="81a9" class="graf graf--p graf-after--figure">From above table we construct a graph which consists of all flight landing at aforementioned time.</p><figure name="fff6" id="fff6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*8mwVuckElWO8xkoz0XLBSQ.png" data-width="1386" data-height="968" src="https://cdn-images-1.medium.com/max/800/1*8mwVuckElWO8xkoz0XLBSQ.png"></figure><h3 name="7ba5" id="7ba5" class="graf graf--h3 graf-after--figure">AWS(Amazon Web Service):</h3><figure name="ecbb" id="ecbb" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*z3AdCo4IojGNezkdxhhNww.png" data-width="552" data-height="508" src="https://cdn-images-1.medium.com/max/800/1*z3AdCo4IojGNezkdxhhNww.png"><figcaption class="imageCaption">google.com</figcaption></figure><h4 name="6e5f" id="6e5f" class="graf graf--h4 graf--empty graf-after--figure"><br></h4><p name="ac1d" id="ac1d" class="graf graf--p graf-after--h4">AWS is a cloud service from Amazon, which provides services including computing, storage, networking, database, analytics etc.. It is also used to form the building blocks to create and deploy any type of applications in the cloud. Building blocks are actully designed to work with each other, and result in applications that are sophisticated and highly scalable.</p><h4 name="7082" id="7082" class="graf graf--h4 graf-after--p">Update all the python code into AWS interface:</h4><p name="3ca9" id="3ca9" class="graf graf--p graf-after--h4">The beauty of this article is to update all the python code into AWS Lambda function to generate all the information automatically according to our choices. I generate all my code to find details of airports and the planes landing for next nine hours. With this output I generate two tables:one consists number of flights arriving in the airport along with weather informations and another with the similar informations but hourly. We can easily get the time of big demands of the scooters from hourly detail. We follow the following instructions to obtain our results:</p><h4 name="a48c" id="a48c" class="graf graf--h4 graf-after--p">1. Set the Lambda function on AWS:</h4><p name="ace7" id="ace7" class="graf graf--p graf-after--h4">Once you have created an account in AWS you have to set a Lambda function. The Lambda function you have created does not cosists some of the python libraries, so you have to add these libraries on Add layer which you can find below on Lmbda function.</p><figure name="de4a" id="de4a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*omNGOsi_lfWBxzgLFF9pZA.png" data-width="1850" data-height="584" src="https://cdn-images-1.medium.com/max/800/1*omNGOsi_lfWBxzgLFF9pZA.png"></figure><h4 name="bba8" id="bba8" class="graf graf--h4 graf-after--figure">2. Generate the python code:</h4><p name="8ce5" id="8ce5" class="graf graf--p graf-after--h4">Once you have added the pyhton libraries you just need to set your code to lambda_function.py as shown nelow:</p><figure name="2524" id="2524" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*bKRGyGwCGL4kvmd2XK9L8A.png" data-width="1872" data-height="602" src="https://cdn-images-1.medium.com/max/800/1*bKRGyGwCGL4kvmd2XK9L8A.png"></figure><p name="98c5" id="98c5" class="graf graf--p graf-after--figure">Apply <strong class="markup--strong markup--p-strong">Deploy</strong> button to save your code and then pess <strong class="markup--strong markup--p-strong">Test</strong> button to produce the result which you require. One can set here the time accordingly to get the results when ever required.</p><h4 name="f886" id="f886" class="graf graf--h4 graf-after--p">3. Add Trigger:</h4><p name="6067" id="6067" class="graf graf--p graf-after--h4">In the Lambda function, we create an event trigger</p><figure name="70e5" id="70e5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xZ5907j6N8V39by2TSSWXg.png" data-width="1684" data-height="448" src="https://cdn-images-1.medium.com/max/800/1*xZ5907j6N8V39by2TSSWXg.png"></figure><p name="4cc6" id="4cc6" class="graf graf--p graf-after--figure">using <strong class="markup--strong markup--p-strong">CloudWatch Events </strong>to produce the results regulary to set the plan for car/scooter companies to optimize the costs regularly. For example, I modify my code to collect all informations in the time between 0:00 to 23:59 every next day. </p><h4 name="1a7d" id="1a7d" class="graf graf--h4 graf-after--p">Contact:</h4><h4 name="2334" id="2334" class="graf graf--h4 graf-after--h4">Github: <a href="https://github.com/aslam7861" data-href="https://github.com/aslam7861" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">https://github.com/aslam7861</a></h4><p name="979b" id="979b" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Email: aliaslam9439@gmail.com</strong></p><p name="1129" id="1129" class="graf graf--p graf--empty graf-after--p"><br></p><p name="4f1c" id="4f1c" class="graf graf--p graf--empty graf-after--p"><br></p><p name="b42d" id="b42d" class="graf graf--p graf--empty graf-after--p"><br></p><p name="b8b1" id="b8b1" class="graf graf--p graf--empty graf-after--p"><br></p><p name="5d1a" id="5d1a" class="graf graf--p graf--empty graf-after--p graf--trailing"><br></p></div></div></section>
</section>
<footer><p><a href="https://medium.com/p/338dbb7f22bc">View original.</a></p><p>Exported from <a href="https://medium.com">Medium</a> on August 11, 2022.</p></footer></article></body></html>